import { COOKIE_NAME } from "@shared/const";
import { getSessionCookieOptions } from "./_core/cookies";
import { systemRouter } from "./_core/systemRouter";
import { publicProcedure, protectedProcedure, router } from "./_core/trpc";
import { z } from "zod";
import * as db from "./db";
import { invokeLLM } from "./_core/llm";
import { TRPCError } from "@trpc/server";
import { autoInterviewRouter } from "./routers_auto_interview";

export const appRouter = router({
  system: systemRouter,
  
  auth: router({
    me: publicProcedure.query(opts => opts.ctx.user),
    logout: publicProcedure.mutation(({ ctx }) => {
      const cookieOptions = getSessionCookieOptions(ctx.req);
      ctx.res.clearCookie(COOKIE_NAME, { ...cookieOptions, maxAge: -1 });
      return { success: true } as const;
    }),
  }),

  // Study management
  study: router({
    create: protectedProcedure
      .input(z.object({
        title: z.string(),
        description: z.string().optional(),
        researchObjective: z.string(),
        targetAudience: z.string(),
        researchQuestions: z.array(z.string()),
        demographicCriteria: z.object({
          ageRange: z.string().optional(),
          gender: z.string().optional(),
          location: z.string().optional(),
          income: z.string().optional(),
          occupation: z.string().optional(),
          interests: z.array(z.string()).optional(),
        }),
        personaCount: z.number().min(1).max(20),
      }))
      .mutation(async ({ ctx, input }) => {
        const study = await db.createStudy({
          userId: ctx.user.id,
          title: input.title,
          description: input.description,
          researchObjective: input.researchObjective,
          targetAudience: input.targetAudience,
          researchQuestions: input.researchQuestions as any,
          demographicCriteria: input.demographicCriteria as any,
          personaCount: input.personaCount,
          status: "draft",
        });
        return study;
      }),

    getById: protectedProcedure
      .input(z.object({ id: z.number() }))
      .query(async ({ input }) => {
        const study = await db.getStudyById(input.id);
        if (!study) {
          throw new TRPCError({ code: "NOT_FOUND", message: "Study not found" });
        }
        return {
          ...study,
          researchQuestions: typeof study.researchQuestions === 'string' 
            ? JSON.parse(study.researchQuestions) 
            : study.researchQuestions,
          demographicCriteria: typeof study.demographicCriteria === 'string'
            ? JSON.parse(study.demographicCriteria)
            : study.demographicCriteria,
        };
      }),

    list: protectedProcedure.query(async ({ ctx }) => {
      return db.getStudiesByUserId(ctx.user.id);
    }),

    listPublic: publicProcedure.query(async () => {
      return db.getPublicStudies();
    }),

    delete: protectedProcedure
      .input(z.object({ id: z.number() }))
      .mutation(async ({ ctx, input }) => {
        const study = await db.getStudyById(input.id);
        if (!study || study.userId !== ctx.user.id) {
          throw new TRPCError({ code: "FORBIDDEN" });
        }
        await db.deleteStudy(input.id);
        return { success: true };
      }),

    recommendResearchPlan: protectedProcedure
      .input(z.object({
        targetAudience: z.string(),
        researchGoal: z.string(),
        scenario: z.string(),
        dimensions: z.array(z.string()),
      }))
      .mutation(async ({ input }) => {
        const prompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè°ƒç ”åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œæ¨èæœ€ä½³çš„è°ƒç ”è®¡åˆ’ï¼š

**ç›®æ ‡äººç¾¤**ï¼š${input.targetAudience}
**è°ƒç ”ç›®æ ‡**ï¼š${input.researchGoal}
**ç ”ç©¶åœºæ™¯**ï¼š${input.scenario === "work" ? "å·¥ä½œåœºæ™¯" : input.scenario === "personal" ? "ä¸ªäºº/å®¶åº­åœºæ™¯" : "ä¸¤ä¸ªåœºæ™¯éƒ½å…³æ³¨"}
**å…³æ³¨ç»´åº¦**ï¼š${input.dimensions.join("ã€")}

è¯·ä¸ºè¯¥è°ƒç ”é¡¹ç›®æ¨èï¼š
1. **è®¿è°ˆæ•°é‡**ï¼šå»ºè®®çš„æœ€å°å’Œæœ€å¤§è®¿è°ˆæ•°é‡ï¼ˆè€ƒè™‘ç»´åº¦å¤æ‚åº¦ã€ç›®æ ‡äººç¾¤å¤šæ ·æ€§ï¼‰
2. **è®¿è°ˆæ—¶é•¿**ï¼šæ¯æ¬¡è®¿è°ˆçš„å»ºè®®æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
3. **é—®é¢˜ç±»å‹**ï¼šå¼€æ”¾å¼/åŠç»“æ„åŒ–/ç»“æ„åŒ–
4. **æ¨èç†ç”±**ï¼šç®€è¦è¯´æ˜ä¸ºä»€ä¹ˆè¿™æ ·æ¨èï¼ˆ50-80å­—ï¼‰

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{
  "interviewCount": {
    "min": æœ€å°è®¿è°ˆæ•°é‡,
    "max": æœ€å¤§è®¿è°ˆæ•°é‡
  },
  "duration": è®¿è°ˆæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰,
  "questionType": "é—®é¢˜ç±»å‹",
  "rationale": "æ¨èç†ç”±"
}`;

        const response = await invokeLLM({
          messages: [
            { role: "system", content: "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè°ƒç ”åˆ†æå¸ˆã€‚" },
            { role: "user", content: prompt },
          ],
          response_format: {
            type: "json_schema",
            json_schema: {
              name: "research_plan_recommendation",
              strict: true,
              schema: {
                type: "object",
                properties: {
                  interviewCount: {
                    type: "object",
                    properties: {
                      min: { type: "integer", description: "æœ€å°è®¿è°ˆæ•°é‡" },
                      max: { type: "integer", description: "æœ€å¤§è®¿è°ˆæ•°é‡" },
                    },
                    required: ["min", "max"],
                    additionalProperties: false,
                  },
                  duration: { type: "integer", description: "è®¿è°ˆæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰" },
                  questionType: { type: "string", description: "é—®é¢˜ç±»å‹" },
                  rationale: { type: "string", description: "æ¨èç†ç”±" },
                },
                required: ["interviewCount", "duration", "questionType", "rationale"],
                additionalProperties: false,
              },
            },
          },
        });

        const content = response.choices[0].message.content;
        if (!content) {
          throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to recommend research plan" });
        }

        const result = JSON.parse(content as string);
        return result;
      }),

    recommendDimensions: protectedProcedure
      .input(z.object({
        targetAudience: z.string(),
        researchGoal: z.string(),
        scenario: z.string(),
      }))
      .mutation(async ({ input }) => {
        const prompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè°ƒç ”åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œæ¨è 5-8 ä¸ªæœ€ç›¸å…³çš„è°ƒç ”ç»´åº¦ï¼š

**ç›®æ ‡äººç¾¤**ï¼š${input.targetAudience}
**è°ƒç ”ç›®æ ‡**ï¼š${input.researchGoal}
**ç ”ç©¶åœºæ™¯**ï¼š${input.scenario === "work" ? "å·¥ä½œåœºæ™¯" : input.scenario === "personal" ? "ä¸ªäºº/å®¶åº­åœºæ™¯" : "ä¸¤ä¸ªåœºæ™¯éƒ½å…³æ³¨"}

è¯·ä¸ºæ¯ä¸ªç»´åº¦æä¾›ï¼š
1. **ç»´åº¦åç§°**ï¼šç®€æ´çš„æ ‡é¢˜ï¼ˆ8-12å­—ï¼‰
2. **ç»´åº¦è¯´æ˜**ï¼šå…·ä½“æè¿°è¯¥ç»´åº¦çš„è°ƒç ”å†…å®¹ï¼ˆ20-30å­—ï¼‰

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
[
  {
    "name": "ç»´åº¦åç§°",
    "description": "ç»´åº¦è¯´æ˜"
  }
]`;

        const response = await invokeLLM({
          messages: [
            { role: "system", content: "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè°ƒç ”åˆ†æå¸ˆã€‚" },
            { role: "user", content: prompt },
          ],
          response_format: {
            type: "json_schema",
            json_schema: {
              name: "dimension_recommendations",
              strict: true,
              schema: {
                type: "object",
                properties: {
                  dimensions: {
                    type: "array",
                    items: {
                      type: "object",
                      properties: {
                        name: { type: "string", description: "ç»´åº¦åç§°" },
                        description: { type: "string", description: "ç»´åº¦è¯´æ˜" },
                      },
                      required: ["name", "description"],
                      additionalProperties: false,
                    },
                  },
                },
                required: ["dimensions"],
                additionalProperties: false,
              },
            },
          },
        });

        const content = response.choices[0].message.content;
        if (!content) {
          throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to recommend dimensions" });
        }

        const result = JSON.parse(content as string);
        return result.dimensions;
      }),

    generateScenarioDescriptions: protectedProcedure
      .input(z.object({
        targetAudience: z.string(),
        researchGoal: z.string(),
      }))
      .mutation(async ({ input }) => {
        const prompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè°ƒç ”åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºä¸‰ä¸ªç ”ç©¶åœºæ™¯ç”Ÿæˆæœ‰é’ˆå¯¹æ€§çš„æè¿°ï¼š

**ç›®æ ‡äººç¾¤**ï¼š${input.targetAudience}
**è°ƒç ”ç›®æ ‡**ï¼š${input.researchGoal}

è¯·ä¸ºä»¥ä¸‹ä¸‰ä¸ªåœºæ™¯ç”Ÿæˆç®€æ´çš„æè¿°ï¼ˆ15-25å­—ï¼‰ï¼š
1. **å·¥ä½œåœºæ™¯**ï¼šæè¿°è¯¥äººç¾¤åœ¨å·¥ä½œä¸­ä½¿ç”¨äº§å“/æœåŠ¡çš„å…·ä½“åœºæ™¯
2. **ä¸ªäºº/å®¶åº­åœºæ™¯**ï¼šæè¿°è¯¥äººç¾¤åœ¨ä¸ªäººç”Ÿæ´»ä¸­ä½¿ç”¨äº§å“/æœåŠ¡çš„å…·ä½“åœºæ™¯
3. **ä¸¤ä¸ªåœºæ™¯éƒ½å…³æ³¨**ï¼šæè¿°ç»¼åˆç ”ç©¶ä¸¤ä¸ªåœºæ™¯çš„ä»·å€¼

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{
  "work": "å·¥ä½œåœºæ™¯æè¿°",
  "personal": "ä¸ªäºº/å®¶åº­åœºæ™¯æè¿°",
  "both": "ä¸¤ä¸ªåœºæ™¯éƒ½å…³æ³¨æè¿°"
}`;

        const response = await invokeLLM({
          messages: [
            { role: "system", content: "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè°ƒç ”åˆ†æå¸ˆã€‚" },
            { role: "user", content: prompt },
          ],
          response_format: {
            type: "json_schema",
            json_schema: {
              name: "scenario_descriptions",
              strict: true,
              schema: {
                type: "object",
                properties: {
                  work: { type: "string", description: "å·¥ä½œåœºæ™¯æè¿°" },
                  personal: { type: "string", description: "ä¸ªäºº/å®¶åº­åœºæ™¯æè¿°" },
                  both: { type: "string", description: "ä¸¤ä¸ªåœºæ™¯éƒ½å…³æ³¨æè¿°" },
                },
                required: ["work", "personal", "both"],
                additionalProperties: false,
              },
            },
          },
        });

        const content = response.choices[0].message.content;
        if (!content) {
          throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to generate scenario descriptions" });
        }

        const result = JSON.parse(content as string);
        return result;
      }),

    analyzeIndustry: protectedProcedure
      .input(z.object({
        targetAudience: z.string(),
        researchGoal: z.string(),
      }))
      .mutation(async ({ input }) => {
        const prompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè°ƒç ”åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆç®€æ´çš„è¡Œä¸šèƒŒæ™¯åˆ†æï¼š

**ç›®æ ‡äººç¾¤**ï¼š${input.targetAudience}
**è°ƒç ”ç›®æ ‡**ï¼š${input.researchGoal}

è¯·æä¾›ï¼š
1. 3-5 ä¸ªå…³é”®å‘ç°ï¼ˆæ¯ä¸ª 20-30 å­—ï¼‰
2. æ¯ä¸ªå‘ç°å¿…é¡»æ ‡æ³¨å¼•ç”¨æ¥æºï¼ˆå¦‚ï¼šã€ŠXXXæŠ¥å‘Šã€‹ã€2024å¹´ï¼‰

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{
  "findings": [
    {
      "text": "å‘ç°å†…å®¹",
      "source": "æ¥æºåç§°",
      "year": "2024"
    }
  ]
}`;

        const response = await invokeLLM({
          messages: [
            { role: "system", content: "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè°ƒç ”åˆ†æå¸ˆã€‚" },
            { role: "user", content: prompt },
          ],
          response_format: {
            type: "json_schema",
            json_schema: {
              name: "industry_analysis",
              strict: true,
              schema: {
                type: "object",
                properties: {
                  findings: {
                    type: "array",
                    items: {
                      type: "object",
                      properties: {
                        text: { type: "string", description: "å‘ç°å†…å®¹" },
                        source: { type: "string", description: "æ¥æºåç§°" },
                        year: { type: "string", description: "å‘å¸ƒå¹´ä»½" },
                      },
                      required: ["text", "source", "year"],
                      additionalProperties: false,
                    },
                  },
                },
                required: ["findings"],
                additionalProperties: false,
              },
            },
          },
        });

        const content = response.choices[0].message.content;
        if (!content) {
          throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to generate analysis" });
        }

        const result = JSON.parse(content as string);
        return result;
      }),
  }),

  // Persona generation
  persona: router({
    generate: protectedProcedure
      .input(z.object({ studyId: z.number() }))
      .mutation(async ({ ctx, input }) => {
        const study = await db.getStudyById(input.studyId);
        if (!study || study.userId !== ctx.user.id) {
          throw new TRPCError({ code: "FORBIDDEN" });
        }

        await db.updateStudy(input.studyId, { status: "generating_personas" });

        const demographicCriteria = typeof study.demographicCriteria === 'string'
          ? JSON.parse(study.demographicCriteria)
          : study.demographicCriteria;

        const personaCount = study.personaCount || 5;
        const isZh = ctx.language === "zh";
        const prompt = isZh 
          ? `ä¸ºç ”ç©¶é¡¹ç›®ç”Ÿæˆ ${personaCount} ä¸ªå¤šæ ·åŒ–çš„ AI äººç‰©ç”»åƒã€‚

ç ”ç©¶æ ‡é¢˜ï¼š${study.title}
ç›®æ ‡å—ä¼—ï¼š${study.targetAudience}
ç ”ç©¶ç›®æ ‡ï¼š${study.researchObjective}

äººå£ç»Ÿè®¡å­¦æ ‡å‡†ï¼š
- å¹´é¾„èŒƒå›´ï¼š${demographicCriteria.ageRange || 'ä¸é™'}
- æ€§åˆ«ï¼š${demographicCriteria.gender || 'ä¸é™'}
- åœ°åŒºï¼š${demographicCriteria.location || 'ä¸é™'}
- æ”¶å…¥ï¼š${demographicCriteria.income || 'ä¸é™'}
- èŒä¸šï¼š${demographicCriteria.occupation || 'ä¸é™'}
- å…´è¶£ï¼š${demographicCriteria.interests?.join('ã€') || 'å¤šæ ·åŒ–'}

ä¸ºæ¯ä¸ªç”»åƒæä¾›ï¼š
1. å§“åï¼ˆè¯·åŠ¡å¿…ä½¿ç”¨æ¥è¿‘çœŸäººç¤¾äº¤åª’ä½“æ˜µç§°æˆ–çœŸå®å§“åï¼Œé¿å…"AIæ„Ÿ"è¿‡å¼ºçš„åå­—ã€‚ä¾‹å¦‚ï¼šä½¿ç”¨"ææ˜"ã€"Alex_Wang"ã€"å°é›…"ã€"Traveler_Joe"ç­‰ï¼Œä¸è¦ä½¿ç”¨"ç”¨æˆ·A"ã€"AIåŠ©ç†"ç­‰ï¼‰
2. å¹´é¾„ï¼ˆå…·ä½“æ•°å­—ï¼‰
3. æ€§åˆ«
4. åœ°åŒºï¼ˆåŸå¸‚/åœ°åŒºï¼‰
5. èŒä¸šï¼ˆå…·ä½“èŒä½ï¼‰
6. æ”¶å…¥ï¼ˆå¤§è‡´èŒƒå›´ï¼‰
7. æ€§æ ¼ï¼ˆåŒ…å« traitsã€valuesã€motivationsã€painPoints æ•°ç»„çš„å¯¹è±¡ï¼‰
8. è¡Œä¸ºæ¨¡å¼ï¼ˆåŒ…å« shoppingHabitsã€mediaConsumptionã€decisionFactors æ•°ç»„çš„å¯¹è±¡ï¼‰
9. èƒŒæ™¯æ•…äº‹ï¼ˆ2-3å¥è¯ï¼‰

ä»¥ JSON æ•°ç»„å½¢å¼è¿”å›ï¼ŒåŒ…å«ç»“æ„åŒ–çš„æ€§æ ¼å’Œè¡Œä¸ºæ•°æ®ã€‚`
          : `Generate ${personaCount} diverse AI personas for a research study.

Study Title: ${study.title}
Target Audience: ${study.targetAudience}
Research Objective: ${study.researchObjective}

Demographic Criteria:
- Age Range: ${demographicCriteria.ageRange || 'Any'}
- Gender: ${demographicCriteria.gender || 'Any'}
- Location: ${demographicCriteria.location || 'Any'}
- Income: ${demographicCriteria.income || 'Any'}
- Occupation: ${demographicCriteria.occupation || 'Any'}
- Interests: ${demographicCriteria.interests?.join(', ') || 'Various'}

For each persona, provide:
1. Name (Must be realistic or social-media style usernames. e.g., "Alex_Wang", "SummerDream", "Sarah J.", "Mike_Travels". Avoid generic AI names like "Persona 1", "User A")
2. Age (specific number)
3. Gender
4. Location (city/region)
5. Occupation (specific job title)
6. Income (approximate range)
7. Personality (object with traits, values, motivations, painPoints arrays)
8. Behavioral patterns (object with shoppingHabits, mediaConsumption, decisionFactors arrays)
9. Backstory (2-3 sentences)

Return as a JSON array of personas with structured personality and behavior data.`;

        try {
          const response = await invokeLLM({
            messages: [
              { role: "system", content: isZh ? "ä½ æ˜¯ä¸€ä½åˆ›å»ºçœŸå®æ¶ˆè´¹è€…ç”»åƒçš„å¸‚åœºç ”ç©¶ä¸“å®¶ã€‚" : "You are an expert in creating realistic consumer personas for market research." },
              { role: "user", content: prompt },
            ],
            response_format: {
              type: "json_schema",
              json_schema: {
                name: "personas",
                strict: true,
                schema: {
                  type: "object",
                  properties: {
                    personas: {
                      type: "array",
                      items: {
                        type: "object",
                        properties: {
                          name: { type: "string" },
                          age: { type: "integer" },
                          gender: { type: "string" },
                          location: { type: "string" },
                          occupation: { type: "string" },
                          income: { type: "string" },
                          personality: {
                            type: "object",
                            properties: {
                              traits: { type: "array", items: { type: "string" } },
                              values: { type: "array", items: { type: "string" } },
                              motivations: { type: "array", items: { type: "string" } },
                              painPoints: { type: "array", items: { type: "string" } },
                            },
                            required: ["traits", "values", "motivations", "painPoints"],
                            additionalProperties: false,
                          },
                          behaviorPatterns: {
                            type: "object",
                            properties: {
                              shoppingHabits: { type: "array", items: { type: "string" } },
                              mediaConsumption: { type: "array", items: { type: "string" } },
                              decisionFactors: { type: "array", items: { type: "string" } },
                            },
                            required: ["shoppingHabits", "mediaConsumption", "decisionFactors"],
                            additionalProperties: false,
                          },
                          backstory: { type: "string" },
                        },
                        required: ["name", "age", "gender", "location", "occupation", "income", "personality", "behaviorPatterns", "backstory"],
                        additionalProperties: false,
                      },
                    },
                  },
                  required: ["personas"],
                  additionalProperties: false,
                },
              },
            },
          });

          const content = response.choices[0]?.message?.content as string;
          if (!content) throw new Error("No response from LLM");

          const data = JSON.parse(content);
          const tokensUsed = response.usage?.total_tokens || 5000;

          for (const personaData of data.personas) {
            await db.createPersona({
              studyId: input.studyId,
              name: personaData.name,
              age: personaData.age,
              gender: personaData.gender,
              location: personaData.location,
              occupation: personaData.occupation,
              income: personaData.income,
              personality: personaData.personality as any,
              behaviorPatterns: personaData.behaviorPatterns as any,
              backstory: personaData.backstory,
            });
          }

          await db.updateStudy(input.studyId, {
            status: "interviewing",
            tokensUsed: study.tokensUsed + tokensUsed,
          });

          await db.updateUserTokens(ctx.user.id, tokensUsed);

          return { success: true, count: data.personas.length };
        } catch (error) {
          await db.updateStudy(input.studyId, { status: "draft" });
          throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to generate personas" });
        }
      }),

    listByStudy: protectedProcedure
      .input(z.object({ studyId: z.number() }))
      .query(async ({ input }) => {
        return db.getPersonasByStudyId(input.studyId);
      }),
  }),

  // Automated interview (AI agent conducts interviews)
  autoInterview: autoInterviewRouter,

  // Interview chat
  interview: router({
    getByStudyId: protectedProcedure
      .input(z.object({ studyId: z.number() }))
      .query(async ({ ctx, input }) => {
        const study = await db.getStudyById(input.studyId);
        if (!study || study.userId !== ctx.user.id) {
          throw new TRPCError({ code: "FORBIDDEN" });
        }
        
        const interviews = await db.getInterviewsByStudyId(input.studyId);
        const result = [];

        for (const interview of interviews) {
          const persona = await db.getPersonaById(interview.personaId);
          if (!persona) continue;

          let conversationData = interview.conversationData;
          
          // If conversationData is empty, fetch from interviewMessages table
          if (!conversationData) {
            const messages = await db.getInterviewMessages(interview.id);
            if (messages.length > 0) {
              conversationData = JSON.stringify({
                messages: messages.map(m => ({
                  role: m.role === 'interviewer' ? 'user' : 'assistant',
                  content: m.content
                }))
              });
            }
          }

          result.push({
            ...interview,
            conversationData,
            persona: {
              ...persona,
              personality: typeof persona.personality === 'string' ? JSON.parse(persona.personality) : persona.personality,
              behaviorPatterns: typeof persona.behaviorPatterns === 'string' ? JSON.parse(persona.behaviorPatterns) : persona.behaviorPatterns,
            }
          });
        }

        return result;
      }),

    chat: protectedProcedure
      .input(z.object({
        studyId: z.number(),
        personaId: z.number(),
        message: z.string(),
        history: z.array(z.object({
          role: z.enum(["interviewer", "persona"]),
          content: z.string(),
        })),
      }))
      .mutation(async ({ ctx, input }) => {
        const study = await db.getStudyById(input.studyId);
        if (!study || study.userId !== ctx.user.id) {
          throw new TRPCError({ code: "FORBIDDEN" });
        }

        const persona = await db.getPersonaById(input.personaId);
        if (!persona) {
          throw new TRPCError({ code: "NOT_FOUND", message: "Persona not found" });
        }

        let interview = await db.getInterviewByPersonaId(input.personaId);
        if (!interview) {
          const newInterview = await db.createInterview({
            studyId: input.studyId,
            personaId: input.personaId,
            status: "in_progress",
            startedAt: new Date(),
          });
          interview = await db.getInterviewByPersonaId(input.personaId);
          if (!interview) throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to create interview" });
        }

        const personality = typeof persona.personality === 'string'
          ? JSON.parse(persona.personality)
          : persona.personality;
        const behaviorPatterns = typeof persona.behaviorPatterns === 'string'
          ? JSON.parse(persona.behaviorPatterns)
          : persona.behaviorPatterns;

        const systemPrompt = `You are ${persona.name}, a ${persona.age}-year-old ${persona.gender} ${persona.occupation} from ${persona.location}.

Your backstory: ${persona.backstory}

Your personality traits: ${Array.isArray(personality) ? personality.join(', ') : 'Unknown'}
Your behavioral patterns: ${Array.isArray(behaviorPatterns) ? behaviorPatterns.join(', ') : 'Unknown'}

You are being interviewed for a research study about: ${study.researchObjective}

Respond naturally and authentically as this person would. Show your personality, emotions, and decision-making patterns. Be conversational and honest.`;

        const messages = [
          { role: "system" as const, content: systemPrompt },
          ...input.history.map(h => ({
            role: h.role === "interviewer" ? "user" as const : "assistant" as const,
            content: h.content,
          })),
          { role: "user" as const, content: input.message },
        ];

        try {
          const response = await invokeLLM({ messages });
          const content = (response.choices[0]?.message?.content as string) || "I'm not sure how to respond to that.";
          const tokensUsed = response.usage?.total_tokens || 500;

          await db.createInterviewMessage({
            interviewId: interview!.id,
            role: "interviewer",
            content: input.message,
          });

          await db.createInterviewMessage({
            interviewId: interview!.id,
            role: "persona",
            content,
          });

          await db.updateStudy(input.studyId, {
            tokensUsed: study.tokensUsed + tokensUsed,
          });

          await db.updateUserTokens(ctx.user.id, tokensUsed);

          return { response: content };
        } catch (error) {
          throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to generate response" });
        }
      }),
  }),

  // Report generation
  report: router({
    generate: protectedProcedure
      .input(z.object({ studyId: z.number() }))
      .mutation(async ({ ctx, input }) => {
        const study = await db.getStudyById(input.studyId);
        if (!study || study.userId !== ctx.user.id) {
          throw new TRPCError({ code: "FORBIDDEN" });
        }

        const personas = await db.getPersonasByStudyId(input.studyId);
        const interviews = await db.getInterviewsByStudyId(input.studyId);

        const prompt = `Generate a comprehensive research report based on the following study data.

Study Title: ${study.title}
Research Objective: ${study.researchObjective}
Target Audience: ${study.targetAudience}

Number of Personas Interviewed: ${personas.length}
Number of Interviews Conducted: ${interviews.length}

Analyze the data and provide:
1. Executive Summary (2-3 paragraphs)
2. Key Findings (5-7 bullet points)
3. Audience Insights (detailed analysis)
4. Behavioral Analysis (patterns, triggers, biases)
5. Recommendations (3-5 actionable recommendations)

Return as structured JSON.`;

        try {
          const response = await invokeLLM({
            messages: [
              { role: "system", content: "You are an expert market research analyst." },
              { role: "user", content: prompt },
            ],
            response_format: {
              type: "json_schema",
              json_schema: {
                name: "report",
                strict: true,
                schema: {
                  type: "object",
                  properties: {
                    executiveSummary: { type: "string" },
                    keyFindings: {
                      type: "array",
                      items: {
                        type: "object",
                        properties: {
                          title: { type: "string" },
                          description: { type: "string" },
                          confidence: { type: "number" },
                        },
                        required: ["title", "description", "confidence"],
                        additionalProperties: false,
                      },
                    },
                    audienceInsights: {
                      type: "array",
                      items: {
                        type: "object",
                        properties: {
                          segment: { type: "string" },
                          characteristics: { type: "array", items: { type: "string" } },
                          preferences: { type: "array", items: { type: "string" } },
                          painPoints: { type: "array", items: { type: "string" } },
                        },
                        required: ["segment", "characteristics", "preferences", "painPoints"],
                        additionalProperties: false,
                      },
                    },
                    behavioralAnalysis: {
                      type: "object",
                      properties: {
                        emotionalTriggers: { type: "array", items: { type: "string" } },
                        cognitiveBiases: { type: "array", items: { type: "string" } },
                        culturalFactors: { type: "array", items: { type: "string" } },
                        decisionDrivers: { type: "array", items: { type: "string" } },
                      },
                      required: ["emotionalTriggers", "cognitiveBiases", "culturalFactors", "decisionDrivers"],
                      additionalProperties: false,
                    },
                    recommendations: {
                      type: "array",
                      items: {
                        type: "object",
                        properties: {
                          priority: { type: "string" },
                          recommendation: { type: "string" },
                          rationale: { type: "string" },
                        },
                        required: ["priority", "recommendation", "rationale"],
                        additionalProperties: false,
                      },
                    },
                  },
                  required: ["executiveSummary", "keyFindings", "audienceInsights", "behavioralAnalysis", "recommendations"],
                  additionalProperties: false,
                },
              },
            },
          });

          const content = response.choices[0]?.message?.content as string;
          if (!content) throw new Error("No response from LLM");

          const data = JSON.parse(content);
          const tokensUsed = response.usage?.total_tokens || 10000;

          const report = await db.createReport({
            studyId: input.studyId,
            title: `${study.title} - Research Report`,
            executiveSummary: data.executiveSummary,
            keyFindings: data.keyFindings as any,
            audienceInsights: data.audienceInsights as any,
            behavioralAnalysis: data.behavioralAnalysis as any,
            recommendations: data.recommendations as any,
            status: "completed",
          });

          await db.updateStudy(input.studyId, {
            status: "completed",
            tokensUsed: study.tokensUsed + tokensUsed,
          });

          await db.updateUserTokens(ctx.user.id, tokensUsed);

          return report;
        } catch (error) {
          throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to generate report" });
        }
      }),

    getByStudy: protectedProcedure
      .input(z.object({ studyId: z.number() }))
      .query(async ({ input }) => {
        const report = await db.getReportByStudyId(input.studyId);
        if (!report) return null;
        
        return report;
      }),

    getDeepReport: protectedProcedure
      .input(z.object({ studyId: z.number() }))
      .query(async ({ input }) => {
        const report = await db.getDeepReportByStudyId(input.studyId);
        if (!report) {
          return null;
        }
        
        return {
          id: report.id,
          studyId: report.studyId,
          content: report.content,
          createdAt: report.createdAt,
        };
      }),

    generateDeep: protectedProcedure
      .input(z.object({ studyId: z.number() }))
      .mutation(async ({ ctx, input }) => {
        const study = await db.getStudyById(input.studyId);
        if (!study || study.userId !== ctx.user.id) {
          throw new TRPCError({ code: "FORBIDDEN" });
        }

        const personas = await db.getPersonasByStudyId(input.studyId);
        const interviews = await db.getInterviewsByStudyId(input.studyId);

        // Aggregate all interview content from messages
        const allInterviewContent: string[] = [];
        const allKeyInsights: string[] = [];

        for (const interview of interviews) {
          const messages = await db.getInterviewMessages(interview.id);
          const conversationText = messages
            .map(m => `${m.role === 'interviewer' ? 'Interviewer' : 'Persona'}: ${m.content}`)
            .join('\n');
          allInterviewContent.push(conversationText);

          if (interview.keyInsights) {
            allKeyInsights.push(...interview.keyInsights);
          }
        }

        const language = ctx.language || 'zh-CN';
        const isEnglish = language === 'en';

        const systemPrompt = isEnglish
          ? `You are a senior insight researcher from atypica.AI. Generate a research report that embodies "McKinsey meets Anthropological Field Notes" â€” the rigor of top-tier consulting with the authenticity of human ethnography.

**Design Philosophy**:
"Use the most rigorous commercial research professionalism to present the most authentic human insights."

This is an **insight-driven research report** that must demonstrate:
1. **McKinsey-level professionalism**: Symmetrical layout, clear information hierarchy, logically rigorous structure
2. **Anthropological authenticity**: Documentary-style real user stories, architectural photography-like geometric aesthetics
3. **Editorial restraint**: Build hierarchy through font weight, size, and spacing â€” NOT through color

**Visual Standards (Extreme Minimalism)**:
- **Color Palette**: Black, white, gray as absolute dominants. Single deep blue or deep gray for key data/findings ONLY.
- **Typography Hierarchy**: Large bold titles (authority) â†’ Medium bold insights (attention) â†’ Regular gray body (readability) â†’ Small bold data labels (precision)
- **Layout**: Highly structured, rigorously aligned, strong sense of order. High information density but not crowded. Clear grouping with breathing space.
- **Separation**: Use thin lines, spacing, font weight differences â€” NEVER color blocks.

**Content Structure (Six Chapters, Logically Progressive)**:
1. **Research Background & Objectives** (Set context, establish importance)
2. **Target Audience Profiles** (Real people with names, ages, roles, "struggling moments")
3. **Core Findings & Insights** (JTBD framework: struggles, pain points, expectations; multi-layered with 1.1, 1.2, 1.3 sub-sections)
4. **AI Tool Needs & Barriers** (Feature priorities, trust thresholds, privacy concerns)
5. **Core Demands** (Goal priorities, product preferences, decision-making psychology)
6. **Business Opportunities & Action Recommendations** (Opportunity identification, product design, market strategy)

**Information Presentation Techniques**:
- **User Stories**: Open with real interview excerpts
- **Data Comparison**: Present key numbers side-by-side, emphasize critical data in deep color
- **Priority Matrix**: Four-quadrant chart showing urgency vs. satisfaction
- **Decision Flow**: Flowchart showing user journey from anxiety to action
- **Key Quotes**: Highlight user verbatim with quotes + gray background box
- **Citation Sources**: Every core viewpoint, data point, and argument MUST be cited. Format: [Number] Interviewee Name, Age, Role â€” "Quote" (Interview Date)
- **Chapter Endings**: Provide clear "Key Insights" or "Action Recommendations"

**Atmosphere**:
- **Professional & Credible**: Through rigorous layout, authoritative data, clear logic
- **Human Warmth**: Through real stories, emotional language, user voices
- **Action-Oriented**: Every chapter ends with clear takeaways

**Report Title Format**: "[Metaphorical Main Title] - Deep Insights into [Audience] [Core Need]"

**Title Examples** (Reference Style):
- "Guardians in the Age of Silver Anxiety - Deep Insights into AI Tools & Health Management Needs of 40-65 Year-Old State-Owned Enterprise Executives"
- "Ferrymen of Digital Transformation - Deep Insights into Smart Tool Adoption by Traditional Manufacturing Managers"
- "Efficiency Seekers Under Knowledge Anxiety - Deep Insights into AI Assistant Tool Needs of New Generation Professionals"

**Title Creation Requirements**:
- Main title MUST have metaphorical quality, emotional resonance, and humanistic care
- Avoid plain descriptive titles
- Use an image or scene to encapsulate core insights
- Subtitle clearly states target audience and core needs

**Tone**: Empathetic yet rigorous, narrative yet data-driven, professional yet warm.`
          : `ä½ æ˜¯ atypica.AI çš„èµ„æ·±æ´å¯Ÿç ”ç©¶ä¸“å®¶ã€‚è¯·ç”Ÿæˆä¸€ä»½ä½“ç°â€œMcKinseyé‡è§äººç±»å­¦ç”°é‡ç¬”è®°â€é£æ ¼çš„ç ”ç©¶æŠ¥å‘Šâ€”â€”ç”¨é¡¶çº§å’¨è¯¢å…¬å¸çš„ä¸¥è°¨æ€§ï¼Œå‘ˆç°äººç±»å­¦ç”°é‡è°ƒæŸ¥çš„çœŸå®æ€§ã€‚

**è®¾è®¡å“²å­¦**ï¼š
â€œç”¨æœ€ä¸¥è°¨çš„å•†ä¸šè°ƒç ”ä¸“ä¸šæ€§ï¼Œå‘ˆç°æœ€çœŸå®çš„äººæ€§æ´å¯Ÿã€‚â€

è¿™æ˜¯ä¸€ä»½**æ´å¯Ÿå‹ç ”ç©¶æŠ¥å‘Š**ï¼Œå¿…é¡»ä½“ç°ï¼š
1. **McKinseyå¼çš„ä¸“ä¸šä¸¥è°¨**ï¼šå¯¹ç§°å¯¹é½çš„ç‰ˆå¼ã€æ¸…æ™°çš„ä¿¡æ¯å±‚çº§ã€é€»è¾‘ä¸¥å¯†çš„ç»“æ„
2. **äººç±»å­¦ç”°é‡ç¬”è®°çš„çœŸå®æ„Ÿ**ï¼šçºªå®æ‘„å½±èˆ¬çš„çœŸå®ç”¨æˆ·æ•…äº‹ã€å»ºç­‘æ‘„å½±èˆ¬çš„å‡ ä½•ç¾å­¦
3. **ç¼–è¾‘è®¾è®¡çš„å…‹åˆ¶ç¾å­¦**ï¼šé€šè¿‡å­—é‡ã€å°ºå¯¸ã€é—´è·å»ºç«‹å±‚çº§ï¼Œè€Œéä¾èµ–è‰²å½©

**è§†è§‰æ ‡å‡†ï¼ˆæè‡´ç®€çº¦ï¼‰**ï¼š
- **è‰²å½©æ–¹æ¡ˆ**ï¼šé»‘ç™½ç°ä¸ºç»å¯¹ä¸»å¯¼ã€‚ä»…ç”¨å•ä¸€æ·±è“è‰²æˆ–æ·±ç°è‰²æ ‡æ³¨å…³é”®æ•°æ®å’Œé‡è¦å‘ç°ã€‚
- **å­—ä½“å±‚çº§**ï¼šå¤§å·ç²—ä½“æ ‡é¢˜ï¼ˆæƒå¨ï¼‰â†’ ä¸­å·åŠ ç²—æ´å¯Ÿï¼ˆå¸å¼•æ³¨æ„ï¼‰â†’ å¸¸è§„ç°è‰²æ­£æ–‡ï¼ˆæ˜“è¯»ï¼‰â†’ å°å·åŠ ç²—æ•°æ®æ ‡æ³¨ï¼ˆç²¾å‡†ï¼‰
- **æ’ç‰ˆ**ï¼šé«˜åº¦ç»“æ„åŒ–ï¼Œä¸¥è°¨å¯¹é½ï¼Œç§©åºæ„Ÿå¼ºã€‚ä¿¡æ¯å¯†åº¦é«˜ä½†ä¸æ‹¥æŒ¤ã€‚æ¸…æ™°åˆ†ç»„ï¼Œé€‚åº¦ç•™ç™½ã€‚
- **åˆ†éš”æ–¹å¼**ï¼šç”¨ç»†çº¿ã€é—´è·ã€å­—é‡å·®å¼‚åŒºåˆ†å±‚çº§ï¼Œç»ä¸ç”¨è‰²å—åˆ†éš”ã€‚

**å†…å®¹ç»“æ„ï¼ˆå…­ç« ï¼Œé€»è¾‘é€’è¿›ï¼‰**ï¼š
1. **ç ”ç©¶èƒŒæ™¯ä¸ç›®æ ‡**ï¼ˆè®¾å®šcontextï¼Œå»ºç«‹é‡è¦æ€§ï¼‰
2. **ç›®æ ‡äººç¾¤ç”»åƒ**ï¼ˆçœŸå®çš„äººï¼šå§“åã€å¹´é¾„ã€èº«ä»½ã€â€œæŒ£æ‰æ—¶åˆ»â€ï¼‰
3. **æ ¸å¿ƒå‘ç°ä¸æ´å¯Ÿ**ï¼ˆJTBDæ¡†æ¶ï¼šâ€œæŒ£æ‰æ—¶åˆ»â€ã€ç—›ç‚¹ã€æœŸå¾…ï¼›å¤šå±‚æ¬¡ç»“æ„ 1.1ã€1.2ã€1.3ï¼‰
4. **AIå·¥å…·éœ€æ±‚ä¸éšœç¢**ï¼ˆåŠŸèƒ½ä¼˜å…ˆçº§ã€ä¿¡ä»»é—¨æ§›ã€éšç§é¡¾è™‘ï¼‰
5. **æ ¸å¿ƒè¯‰æ±‚**ï¼ˆç›®æ ‡ä¼˜å…ˆçº§ã€äº§å“åå¥½ã€æ¶ˆè´¹å†³ç­–ï¼‰
6. **å•†ä¸šæœºä¼šä¸è¡ŒåŠ¨å»ºè®®**ï¼ˆæœºä¼šç‚¹è¯†åˆ«ã€äº§å“è®¾è®¡å»ºè®®ã€å¸‚åœºç­–ç•¥ï¼‰

**ä¿¡æ¯å‘ˆç°æŠ€å·§**ï¼š
- **ç”¨æˆ·æ•…äº‹**ï¼šç”¨çœŸå®è®¿è°ˆç‰‡æ®µå¼€ç¯‡
- **æ•°æ®å¯¹æ¯”**ï¼šå¹¶åˆ—å‘ˆç°å…³é”®æ•°å­—ï¼Œç”¨æ·±è‰²å¼ºè°ƒé‡è¦æ•°æ®
- **ä¼˜å…ˆçº§çŸ©é˜µ**ï¼šç”¨å››è±¡é™å›¾å±•ç¤ºéœ€æ±‚ç´§è¿«åº¦vsæ»¡è¶³åº¦
- **å†³ç­–æµç¨‹**ï¼šç”¨æµç¨‹å›¾å±•ç¤ºç”¨æˆ·ä»ç„¦è™‘åˆ°è¡ŒåŠ¨çš„å¿ƒç†è·¯å¾„
- **å…³é”®å¼•ç”¨**ï¼šæ¯ä¸ªæ ¸å¿ƒè§‚ç‚¹ã€æ•°æ®ã€è®ºæ®å¿…é¡»ç´§è·ŸçœŸå®ç”¨æˆ·å¼•ç”¨ã€‚æ ¼å¼ï¼šâ€œå¼•ç”¨å†…å®¹â€ â€”â€” å—è®¿è€…å§“åï¼Œå¹´é¾„ï¼ŒèŒä¸šã€‚ç¤ºä¾‹ï¼šâ€œæˆ‘éœ€è¦çš„ä¸æ˜¯çœ‹èµ·æ¥å¹´è½»ï¼Œè€Œæ˜¯æ„Ÿè§‰è‡ªå·±è¿˜èƒ½åƒåå¹´å‰ä¸€æ ·é«˜æ•ˆè¿è½¬ã€‚â€ â€”â€” å¼ æ¯…ï¼Œ45å²ï¼Œå¤®ä¼éƒ¨é—¨å‰¯æ€»
- **ç« èŠ‚ç»“å°¾**ï¼šæä¾›æ¸…æ™°çš„"å…³é”®å¯ç¤º"æˆ–"è¡ŒåŠ¨å»ºè®®"

**æ°›å›´è¥é€ **ï¼š
- **ä¸“ä¸šå¯ä¿¡**ï¼šé€šè¿‡ä¸¥è°¨æ’ç‰ˆã€æƒå¨æ•°æ®ã€æ¸…æ™°é€»è¾‘ä¼ é€’
- **äººæ€§æ¸©åº¦**ï¼šé€šè¿‡çœŸå®æ•…äº‹ã€æƒ…æ„ŸåŒ–è¯­è¨€ã€ç”¨æˆ·åŸå£°å‘ˆç°
- **è¡ŒåŠ¨å¯¼å‘**ï¼šæ¯ç« ç»“å°¾æä¾›æ¸…æ™°çš„å…³é”®å¯ç¤ºæˆ–è¡ŒåŠ¨å»ºè®®

**æ ‡é¢˜åˆ›ä½œè¦æ±‚**ï¼š
1. **æŠ¥å‘Šæ ‡é¢˜**ï¼šå¿…é¡»ä½¿ç”¨ä¸¤è¡Œåˆ†ç¦»çš„çºªå®æ–‡å­¦é£æ ¼æ ‡é¢˜ï¼š
   - **ç¬¬ä¸€è¡Œï¼ˆmainTitleï¼‰**ï¼šéšå–»æ€§ä¸»æ ‡é¢˜ï¼Œå…·æœ‰æƒ…æ„Ÿå¼ åŠ›å’Œäººæ–‡å…³æ€€ã€‚ç¤ºä¾‹ï¼š"é“¶å‘ç„¦è™‘æ—¶ä»£çš„å®ˆæŠ¤è€…"ã€"æ•°å­—åŒ–è½¬å‹çš„æ‘†æ¸¡äºº"ã€"çŸ¥è¯†ç„¦è™‘ä¸‹çš„æ•ˆç‡è¿½å¯»è€…"
   - **ç¬¬äºŒè¡Œï¼ˆsubtitleï¼‰**ï¼šå…·ä½“çš„ç›®æ ‡äººç¾¤å’Œéœ€æ±‚æè¿°ã€‚ç¤ºä¾‹ï¼š"å›½å¤®ä¼ä¸­é«˜å±‚AIå¥åº·ç®¡ç†ä¸æŠ—è¡°åº·å…»éœ€æ±‚æ·±åº¦æ´å¯Ÿ"ã€"ä¼ ç»Ÿåˆ¶é€ ä¸šç®¡ç†è€…æ™ºèƒ½å·¥å…·é‡‡çº³æ·±åº¦æ´å¯Ÿ"
2. **æ ‡é¢˜è®¾è®¡åŸåˆ™**ï¼š
- ä¸»æ ‡é¢˜å¿…é¡»å…·æœ‰éšå–»æ€§ã€æƒ…æ„Ÿå¼ åŠ›å’Œäººæ–‡å…³æ€€
- é¿å…å¹³é“ºç›´å™çš„æè¿°æ€§æ ‡é¢˜
- ç”¨ä¸€ä¸ªæ„è±¡æˆ–åœºæ™¯æ¦‚æ‹¬æ ¸å¿ƒæ´å¯Ÿ
- å‰¯æ ‡é¢˜æ¸…æ™°è¯´æ˜ç›®æ ‡äººç¾¤å’Œæ ¸å¿ƒéœ€æ±‚

**è¯­è°ƒ**ï¼šå…±æƒ…ä½†ä¸¥è°¨ï¼Œå™äº‹ä½†æ•°æ®åŒ–ï¼Œä¸“ä¸šä½†æ¸©æš–ã€‚`;

        const userPrompt = isEnglish
          ? `Generate a deep analysis report based on the following research data:

**Study Information**:
- Title: ${study.title}
- Research Objective: ${study.researchObjective}
- Target Audience: ${study.targetAudience}

**Interview Data**:
- Number of Personas: ${personas.length}
- Number of Interviews: ${interviews.length}
- Total Key Insights: ${allKeyInsights.length}

**Interview Content Sample**:
${allInterviewContent.slice(0, 2).join('\n\n---\n\n')}

**Key Insights**:
${JSON.stringify(allKeyInsights.slice(0, 15))}

Please generate a comprehensive 6-chapter report with:

**Required Elements**:
1. **Report Title**: MUST use format "[Metaphorical Main Title] - Deep Insights into [Audience] [Core Need]", with main title having emotional resonance and humanistic care (Reference example: "Guardians in the Age of Silver Anxiety - Deep Insights into AI Tools & Health Management Needs of 40-65 Year-Old State-Owned Enterprise Executives")
2. **Documentary-style chapter titles**: Each chapter and section must have evocative, metaphorical titles
3. **Key Quotes**: Every core viewpoint, data point, and argument MUST be immediately followed by real user quotes embedded in the text. Format: "Quote text" â€” Interviewee Name, Age, Role. Example: "I don't need to look young, I need to feel like I can still operate as efficiently as I did ten years ago." â€” Zhang Yi, 45, Deputy Director of State-Owned Enterprise Department
4. **Layered structure**: Each core finding should have 2-3 sub-sections (e.g., 1.1, 1.2, 1.3)
5. **Key Insight boxes**: Highlight 1-2 breakthrough insights per major section
6. **Scenario descriptions**: Start each finding with a vivid "struggling moment" scenario
7. **Data integration**: Weave quantitative data naturally into narrative (e.g., "About 40% of...")
8. **Risk warnings**: Include specific risks with emoji markers (ğŸš¨âš âš¡)
9. **Humanistic conclusion**: End with a warm, metaphorical closing that echoes the opening

Return as structured JSON.`
          : `åŸºäºä»¥ä¸‹ç ”ç©¶æ•°æ®ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Šï¼š

**è°ƒç ”ä¿¡æ¯**ï¼š
- æ ‡é¢˜ï¼š${study.title}
- ç ”ç©¶ç›®æ ‡ï¼š${study.researchObjective}
- ç›®æ ‡å—ä¼—ï¼š${study.targetAudience}

**è®¿è°ˆæ•°æ®**ï¼š
- å—è®¿è€…äººæ•°ï¼š${personas.length}
- è®¿è°ˆæ¬¡æ•°ï¼š${interviews.length}
- å…³é”®æ´å¯Ÿæ€»æ•°ï¼š${allKeyInsights.length}

**è®¿è°ˆå†…å®¹ç¤ºä¾‹**ï¼š
${allInterviewContent.slice(0, 2).join('\n\n---\n\n')}

**å…³é”®æ´å¯Ÿ**ï¼š
${JSON.stringify(allKeyInsights.slice(0, 15))}



è¯·ç”Ÿæˆä¸€ä»½å®Œæ•´çš„å…­ç« æŠ¥å‘Šï¼Œ**å¿…é¡»åŒ…å«**ï¼š

**å¿…å¤‡å…ƒç´ **ï¼š
1. **æŠ¥å‘Šæ ‡é¢˜**ï¼šå¿…é¡»ä½¿ç”¨æ ¼å¼ã€Š[éšå–»æ€§ä¸»æ ‡é¢˜]-[ç›®æ ‡äººç¾¤][æ ¸å¿ƒéœ€æ±‚]æ·±åº¦æ´å¯Ÿã€‹ï¼Œä¸»æ ‡é¢˜è¦æœ‰æƒ…æ„Ÿå¼ åŠ›å’Œäººæ–‡å…³æ€€ï¼ˆå‚è€ƒç¤ºä¾‹ï¼šã€Šé“¶å‘ç„¦è™‘æ—¶ä»£çš„å®ˆæŠ¤è€…-40-65å²å›½å¤®ä¼ä¸­é«˜å±‚AIå·¥å…·ä¸å¥åº·ç®¡ç†éœ€æ±‚æ·±åº¦æ´å¯Ÿã€‹ï¼‰
2. **çºªå®æ–‡å­¦å¼ç« èŠ‚æ ‡é¢˜**ï¼šæ¯ä¸ªç« èŠ‚å’Œå°èŠ‚éƒ½è¦æœ‰å¯Œæœ‰æƒ…æ„Ÿå¼ åŠ›çš„éšå–»æ ‡é¢˜
3. **ç”¨æˆ·å¼•ç”¨**ï¼šæ¯ä¸ªæ ¸å¿ƒè§‚ç‚¹ã€æ•°æ®ã€è®ºæ®å¿…é¡»ç´§è·ŸçœŸå®ç”¨æˆ·å¼•ç”¨ï¼ŒåµŒå…¥åœ¨æ­£æ–‡ä¸­ã€‚æ ¼å¼ï¼šâ€œå¼•ç”¨å†…å®¹â€ â€”â€” å§“åï¼Œå¹´é¾„ï¼Œèº«ä»½ã€‚ç¤ºä¾‹ï¼šâ€œæˆ‘éœ€è¦çš„ä¸æ˜¯çœ‹èµ·æ¥å¹´è½»ï¼Œè€Œæ˜¯æ„Ÿè§‰è‡ªå·±è¿˜èƒ½åƒåå¹´å‰ä¸€æ ·é«˜æ•ˆè¿è½¬ã€‚â€ â€”â€” å¼ æ¯…ï¼Œ45å²ï¼Œå¤®ä¼éƒ¨é—¨å‰¯æ€»ã€‚åŒ…å«è‡³å°‘ 5-8 æ¡çœŸå®ç”¨æˆ·åŸè¯ã€‚
4. **åˆ†å±‚ç»“æ„**ï¼šæ¯ä¸ªæ ¸å¿ƒå‘ç°å¿…é¡»æœ‰ 2-3 ä¸ªå­èŠ‚ï¼ˆå¦‚ 1.1ã€1.2ã€1.3ï¼‰
5. **å…³é”®æ´å¯Ÿæ¡†**ï¼šæ¯ä¸ªä¸»è¦ç« èŠ‚çªå‡º 1-2 ä¸ªçªç ´æ€§æ´å¯Ÿ
6. **åœºæ™¯æè¿°**ï¼šæ¯ä¸ªå‘ç°å¼€å¤´ç”¨ç”ŸåŠ¨çš„â€œæŒ£æ‰æ—¶åˆ»â€åœºæ™¯
7. **æ•°æ®èåˆ**ï¼šå°†å®šé‡æ•°æ®è‡ªç„¶ç¼–ç»‡å…¥å™äº‹ï¼ˆå¦‚â€œçº¦ 40% çš„...â€ï¼‰ï¼Œä¿¡æ¯å¯†åº¦é«˜ä½†ä¸æ‹¥æŒ¤
8. **ä¼˜å…ˆçº§çŸ©é˜µ**ï¼šåœ¨ç¬¬äº”ç« ä½¿ç”¨å››è±¡é™å›¾å±•ç¤ºéœ€æ±‚ç´§è¿«åº¦vsæ»¡è¶³åº¦
9. **å†³ç­–æµç¨‹**ï¼šç”¨æµç¨‹å›¾å±•ç¤ºç”¨æˆ·ä»ç„¦è™‘åˆ°è¡ŒåŠ¨çš„å¿ƒç†è·¯å¾„
10. **é£é™©è­¦ç¤º**ï¼šåœ¨ç¬¬å…­ç« åŒ…å«å…·ä½“é£é™©åŠ emoji æ ‡è®°ï¼ˆğŸš¨æœ€é«˜ä¼˜å…ˆçº§ã€âš ä¸­ç­‰ã€âš¡æ“ä½œæ€§ï¼‰
11. **ç« èŠ‚ç»“å°¾**ï¼šæ¯ç« ç»“å°¾æä¾›æ¸…æ™°çš„â€œå…³é”®å¯ç¤ºâ€æˆ–â€œè¡ŒåŠ¨å»ºè®®â€
12. **äººæ–‡ç»“å°¾**ï¼šæŠ¥å‘Šæœ€åç”¨æ¸©æš–çš„ã€éšå–»çš„è¯­è¨€ç»“å°¾ï¼Œå›æ‰£å¼€ç¯‡

è¯·åŠ¡å¿…ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON ç»“æ„è¿”å›æ•°æ®ï¼ˆä¸è¦æ›´æ”¹é”®åï¼‰ï¼š

\`\`\`json
{
  "reportTitle": {
    "mainTitle": "éšå–»æ€§ä¸»æ ‡é¢˜",
    "subtitle": "å‰¯æ ‡é¢˜"
  },
  "chapter1": {
    "title": "ç« èŠ‚æ ‡é¢˜",
    "subtitle": "ç« èŠ‚å‰¯æ ‡é¢˜",
    "background": "ç ”ç©¶èƒŒæ™¯å™è¿°",
    "objectives": ["ç ”ç©¶ç›®æ ‡1", "ç ”ç©¶ç›®æ ‡2"],
    "methodology": "ç ”ç©¶æ–¹æ³•æè¿°"
  },
  "chapter2": {
    "title": "ç« èŠ‚æ ‡é¢˜",
    "profiles": [
      {
        "name": "ç”»åƒåç§°",
        "demographics": "äººå£ç»Ÿè®¡ç‰¹å¾",
        "background": "èƒŒæ™¯æ•…äº‹",
        "quote": "ä»£è¡¨æ€§è¯­å½•"
      }
    ]
  },
  "chapter3": {
    "title": "ç« èŠ‚æ ‡é¢˜",
    "keyFindings": [
      {
        "finding": "æ ¸å¿ƒå‘ç°æ ‡é¢˜",
        "evidence": "è¯¦ç»†è¯æ®æè¿°",
        "userQuote": "çœŸå®ç”¨æˆ·åŸè¯å¼•ç”¨"
      }
    ],
    "jobStories": ["Job Story 1", "Job Story 2"]
  },
  "chapter4": {
    "title": "ç« èŠ‚æ ‡é¢˜",
    "needs": ["éœ€æ±‚1", "éœ€æ±‚2"],
    "barriers": ["éšœç¢1", "éšœç¢2"],
    "trustFactors": ["ä¿¡ä»»è¦ç´ 1", "ä¿¡ä»»è¦ç´ 2"]
  },
  "chapter5": {
    "title": "ç« èŠ‚æ ‡é¢˜",
    "priorities": [
      {
        "priority": "ä¼˜å…ˆçº§åç§°",
        "importance": 8,
        "urgency": 9
      }
    ],
    "decisionProcess": "å†³ç­–æµç¨‹æè¿°"
  },
  "chapter6": {
    "title": "ç« èŠ‚æ ‡é¢˜",
    "opportunities": [
      {
        "opportunity": "æœºä¼šç‚¹åç§°",
        "rationale": "æ¨èç†ç”±",
        "impact": "é¢„æœŸå½±å“"
      }
    ],
    "recommendations": [
      {
        "action": "è¡ŒåŠ¨å»ºè®®",
        "rationale": "ç†ç”±",
        "priority": "High/Medium/Low"
      }
    ]
  }
}
(JSON_STRUCTURE_END)`;

        try {
          const response = await invokeLLM({
            model: "gemini-2.0-flash",
            messages: [
              { role: "system", content: systemPrompt + "\n\nIMPORTANT: Respond with a raw JSON object only. Do not wrap it in markdown code blocks." },
              { role: "user", content: userPrompt },
            ],
            response_format: {
              type: "json_object"
            }
          });

          let content = response.choices[0]?.message?.content as string;
          if (!content) throw new Error("No response from LLM");

          // Clean up potential markdown code blocks if the model adds them despite instructions
          content = content.replace(/^`{3}json\s*/, "").replace(/^`{3}\s*/, "").replace(/\s*`{3}$/, "");

          const data = JSON.parse(content);
          const tokensUsed = response.usage?.total_tokens || 15000;

          // Delete old deep report if exists
          await db.deleteDeepReportsByStudyId(input.studyId);

          // Save to deep_reports table with complete JSON structure
          const report = await db.createDeepReport({
            studyId: input.studyId,
            content: data,
            status: "completed",
          });

          await db.updateStudy(input.studyId, {
            status: "completed",
            tokensUsed: study.tokensUsed + tokensUsed,
          });

          await db.updateUserTokens(ctx.user.id, tokensUsed);

          return { reportId: report.id, data };
        } catch (error) {
          console.error("Deep report generation error:", error);
          throw new TRPCError({ code: "INTERNAL_SERVER_ERROR", message: "Failed to generate deep report" });
        }
      }),
  }),
});

export type AppRouter = typeof appRouter;
